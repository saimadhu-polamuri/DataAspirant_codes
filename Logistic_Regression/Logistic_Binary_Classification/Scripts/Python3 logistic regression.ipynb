{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# logistic_regression.py\n",
    "# Author : Saimadhu\n",
    "# Date: 19-March-2017\n",
    "# About: Implementing Logistic Regression Classifier to predict to whom the voter will vote.\n",
    "\n",
    "# Required Python Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# import plotly.plotly as py\n",
    "# from plotly.graph_objs import *\n",
    "py.sign_in('dataaspirant', 'RhJdlA1OsXsTjcRA0Kka')\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Files\n",
    "DATA_SET_PATH = \"../Inputs/anes_dataset.csv\"\n",
    "\n",
    "\n",
    "def dataset_headers(dataset):\n",
    "    \"\"\"\n",
    "    To get the dataset header names\n",
    "    :param dataset: loaded dataset into pandas DataFrame\n",
    "    :return: list of header names\n",
    "    \"\"\"\n",
    "    return list(dataset.columns.values)\n",
    "\n",
    "\n",
    "def unique_observations(dataset, header, method=1):\n",
    "    \"\"\"\n",
    "    To get unique observations in the loaded pandas DataFrame column\n",
    "    :param dataset:\n",
    "    :param header:\n",
    "    :param method: Method to perform the unique (default method=1 for pandas and method=0 for numpy )\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if method == 0:\n",
    "            # With Numpy\n",
    "            observations = np.unique(dataset[[header]])\n",
    "        elif method == 1:\n",
    "            # With Pandas\n",
    "            observations = pd.unique(dataset[header].values.ravel())\n",
    "        else:\n",
    "            observations = None\n",
    "            print(\"Wrong method type, Use 1 for pandas and 0 for numpy\")\n",
    "    except Exception as e:\n",
    "        observations = None\n",
    "        print(\"Error: {error_msg} /n Please check the inputs once..!\".format(error_msg=e.message))\n",
    "    return observations\n",
    "\n",
    "\n",
    "def feature_target_frequency_relation(dataset, f_t_headers):\n",
    "\n",
    "    \"\"\"\n",
    "    To get the frequency relation between targets and the unique feature observations\n",
    "    :param dataset:\n",
    "    :param f_t_headers: feature and target header\n",
    "    :return: feature unique observations dictionary of frequency count dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    feature_unique_observations = unique_observations(dataset, f_t_headers[0])\n",
    "    unique_targets = unique_observations(dataset, f_t_headers[1])\n",
    "\n",
    "    frequencies = {}\n",
    "    for feature in feature_unique_observations:\n",
    "        frequencies[feature] = {unique_targets[0]: len(\n",
    "            dataset[(dataset[f_t_headers[0]] == feature) & (dataset[f_t_headers[1]] == unique_targets[0])]),\n",
    "            unique_targets[1]: len(\n",
    "                dataset[(dataset[f_t_headers[0]] == feature) & (dataset[f_t_headers[1]] == unique_targets[1])])}\n",
    "    return frequencies\n",
    "\n",
    "\n",
    "def feature_target_histogram(feature_target_frequencies, feature_header):\n",
    "    \"\"\"\n",
    "\n",
    "    :param feature_target_frequencies:\n",
    "    :param feature_header:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    keys = list(feature_target_frequencies.keys())\n",
    "    y0 = [feature_target_frequencies[key][0] for key in keys]\n",
    "    y1 = [feature_target_frequencies[key][1] for key in keys]\n",
    "\n",
    "    trace1 = go.Bar(\n",
    "        x=keys,\n",
    "        y=y0,\n",
    "        name='Clinton'\n",
    "    )\n",
    "    trace2 = go.Bar(\n",
    "        x=keys,\n",
    "        y=y1,\n",
    "        name='Dole'\n",
    "    )\n",
    "    data = [trace1, trace2]\n",
    "    layout = go.Layout(\n",
    "        barmode='group',\n",
    "        title='Feature :: ' + feature_header + ' Clinton Vs Dole votes Frequency',\n",
    "        xaxis=dict(title=\"Feature :: \" + feature_header + \" classes\"),\n",
    "        yaxis=dict(title=\"Votes Frequency\")\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    # plot_url = py.plot(fig, filename=feature_header + ' - Target - Histogram')\n",
    "    py.image.save_as(fig, filename=feature_header + '_Target_Histogram.png')\n",
    "\n",
    "\n",
    "def train_logistic_regression(train_x, train_y):\n",
    "    \"\"\"\n",
    "    Training logistic regression model with train dataset features(train_x) and target(train_y)\n",
    "    :param train_x:\n",
    "    :param train_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    logistic_regression_model = LogisticRegression()\n",
    "    logistic_regression_model.fit(train_x, train_y)\n",
    "    return logistic_regression_model\n",
    "\n",
    "\n",
    "def model_accuracy(trained_model, features, targets):\n",
    "    \"\"\"\n",
    "    Get the accuracy score of the model\n",
    "    :param trained_model:\n",
    "    :param features:\n",
    "    :param targets:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    accuracy_score = trained_model.score(features, targets)\n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Observations ::  944\n",
      "   popul  TVnews  selfLR  ClinLR  DoleLR  PID  age  educ  income  vote\n",
      "0      0       7       7       1       6    6   36     3       1     1\n",
      "1    190       1       3       3       5    1   20     4       1     0\n",
      "2     31       7       2       2       6    1   24     6       1     0\n",
      "3     83       4       3       4       5    1   28     6       1     0\n",
      "4    640       7       5       6       4    0   68     6       1     0\n",
      "Data set headers :: ['popul', 'TVnews', 'selfLR', 'ClinLR', 'DoleLR', 'PID', 'age', 'educ', 'income', 'vote']\n",
      "train_x size ::  (660, 5)\n",
      "train_y size ::  (660,)\n",
      "test_x size ::  (284, 5)\n",
      "test_y size ::  (284,)\n",
      "edu_target_frequencies ::  {3: {1: 95, 0: 153}, 4: {1: 81, 0: 106}, 6: {1: 108, 0: 119}, 2: {1: 14, 0: 38}, 5: {1: 37, 0: 53}, 1: {1: 3, 0: 10}, 7: {1: 55, 0: 72}}\n",
      "Train Accuracy ::  0.90303030303\n",
      "Test Accuracy ::  0.908450704225\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Logistic Regression classifier main\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Load the data set for training and testing the logistic regression classifier\n",
    "    dataset = pd.read_csv(DATA_SET_PATH)\n",
    "    print(\"Number of Observations :: \", len(dataset))\n",
    "\n",
    "    # Get the first observation\n",
    "    print(dataset.head())\n",
    "\n",
    "    headers = dataset_headers(dataset)\n",
    "    print(\"Data set headers :: {headers}\".format(headers=headers))\n",
    "\n",
    "    training_features = ['TVnews', 'PID', 'age', 'educ', 'income']\n",
    "    target = 'vote'\n",
    "\n",
    "    # Train , Test data split\n",
    "    train_x, test_x, train_y, test_y = train_test_split(dataset[training_features], dataset[target], train_size=0.7)\n",
    "    print(\"train_x size :: \", train_x.shape)\n",
    "    print(\"train_y size :: \", train_y.shape)\n",
    "\n",
    "    print(\"test_x size :: \", test_x.shape)\n",
    "    print(\"test_y size :: \", test_y.shape)\n",
    "\n",
    "    print(\"edu_target_frequencies :: \", feature_target_frequency_relation(dataset, [training_features[3], target]))\n",
    "\n",
    "    for feature in training_features:\n",
    "        feature_target_frequencies = feature_target_frequency_relation(dataset, [feature, target])\n",
    "        feature_target_histogram(feature_target_frequencies, feature)\n",
    "\n",
    "    # Training Logistic regression model\n",
    "    trained_logistic_regression_model = train_logistic_regression(train_x, train_y)\n",
    "\n",
    "    train_accuracy = model_accuracy(trained_logistic_regression_model, train_x, train_y)\n",
    "\n",
    "    # Testing the logistic regression model\n",
    "    test_accuracy = model_accuracy(trained_logistic_regression_model, test_x, test_y)\n",
    "\n",
    "    print(\"Train Accuracy :: \", train_accuracy)\n",
    "    print(\"Test Accuracy :: \", test_accuracy)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:siemens]",
   "language": "python",
   "name": "conda-env-siemens-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
